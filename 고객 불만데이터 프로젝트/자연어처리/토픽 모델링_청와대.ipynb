{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\AppData\\Local\\Temp\\ipykernel_13748\\1858009140.py:2: DtypeWarning: Columns (0,3,4,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,504,553,602,604,663,715,764,813,862,869,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"C:/Users/11/Desktop/데이터 분석가/petition_sampled.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 77, 834, 268, 1266, 855, 1390, 1218, 1042, 1131, 1202, 1184, 1162, 1299, 1082, 1195, 1126, 398] 16730\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/11/Desktop/데이터 분석가/petition_sampled.csv\")\n",
    "df_sorted= df.sort_values(by='start')\n",
    "\n",
    "df_sorted['time'] = df_sorted['start'].map(lambda x: x[:7])\n",
    "\n",
    "time_slice = list(df_sorted['time'].value_counts().sort_index())\n",
    "print(time_slice,sum(time_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 遺\\x80紐? ?',\n",
       " '2017-08',\n",
       " '2017-09',\n",
       " '2017-10',\n",
       " '2017-11',\n",
       " '2017-12',\n",
       " '2018-01',\n",
       " '2018-02',\n",
       " '2018-03',\n",
       " '2018-04',\n",
       " '2018-05',\n",
       " '2018-06',\n",
       " '2018-07',\n",
       " '2018-08',\n",
       " '2018-09',\n",
       " '2018-10',\n",
       " '2018-11',\n",
       " '2018-12']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_tag = sorted(list(set(df_sorted['time'])))\n",
    "time_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "phrase input should be string, not <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(doc):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m twit\u001b[38;5;241m.\u001b[39mnouns(doc) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m] \n\u001b[1;32m----> 7\u001b[0m texts \u001b[38;5;241m=\u001b[39m [tokenizer(news) \u001b[38;5;28;01mfor\u001b[39;00m news \u001b[38;5;129;01min\u001b[39;00m df_sorted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      9\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m Dictionary(texts)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#number of initial unique words in documents:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dictionary))\n",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(doc):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m twit\u001b[38;5;241m.\u001b[39mnouns(doc) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m] \n\u001b[1;32m----> 7\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m news \u001b[38;5;129;01min\u001b[39;00m df_sorted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      9\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m Dictionary(texts)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#number of initial unique words in documents:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dictionary))\n",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mtokenizer\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(doc):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtwit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnouns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\11\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\konlpy\\tag\\_okt.py:83\u001b[0m, in \u001b[0;36mOkt.nouns\u001b[1;34m(self, phrase)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnouns\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase):\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Noun extractor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     tagged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [s \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m tagged \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\11\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\konlpy\\tag\\_okt.py:69\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    In contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    this POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    :param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mvalidate_phrase_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjki\u001b[38;5;241m.\u001b[39mtokenize(\n\u001b[0;32m     72\u001b[0m                 phrase,\n\u001b[0;32m     73\u001b[0m                 jpype\u001b[38;5;241m.\u001b[39mjava\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39mBoolean(norm),\n\u001b[0;32m     74\u001b[0m                 jpype\u001b[38;5;241m.\u001b[39mjava\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39mBoolean(stem))\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m join:\n",
      "File \u001b[1;32mc:\\Users\\11\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\konlpy\\tag\\_common.py:20\u001b[0m, in \u001b[0;36mvalidate_phrase_inputs\u001b[1;34m(phrase)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"validate if phrase input is provided in str format\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    phrase (str): phrase input\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrase input should be string, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(phrase)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(phrase, basestring), msg\n",
      "\u001b[1;31mAssertionError\u001b[0m: phrase input should be string, not <class 'float'>"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from konlpy.tag import Okt\n",
    "twit = Okt()\n",
    "\n",
    "def tokenizer(doc):\n",
    "    return [token for token in twit.nouns(doc) if len(token) > 1] \n",
    "texts = [tokenizer(news) for news in df_sorted['content']]\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "print('#number of initial unique words in documents:', len(dictionary))\n",
    "\n",
    "dictionary.filter_extremes(keep_n=2000, no_below=5, no_above=0.5)\n",
    "print('#number of unique words after removing rare and common words:', len(dictionary))\n",
    "\n",
    "copus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(' #number of unique tokens: %d' %len(dictionary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
